# Conversation Analysis Test Suite

This directory contains comprehensive tests for the conversation analysis pipeline, including unit tests, functional tests, and integration tests.

## Test Organization

### Unit Tests
- **`test_hierarchical_hypothesis.py`**: Tests for the hierarchical hypothesis testing framework
  - Fisher transformation methods
  - Cohen's q and Steiger's test implementations
  - Tier 1-3 hypothesis testing logic
  - Control hypothesis tests
  - Null model comparisons

- **`test_paradigm_null_models.py`**: Tests for paradigm-specific null model generation
  - Phase scrambling (preserves power spectrum)
  - Averaging nulls for Word2Vec/GloVe
  - Positional nulls for transformers
  - Dimension matching across paradigms
  - Message-level null models

- **`test_control_analyses.py`**: Tests for control analyses
  - Message length control with partial correlations
  - Conversation type analysis
  - Temporal stability testing
  - Outlier robustness checking
  - Bootstrap confidence intervals

### Functional Tests
- **`test_hypothesis_data_preparation.py`**: Tests data preparation for hypothesis testing
  - Correlation categorization (transformer/classical/cross-paradigm)
  - Geometric metric extraction
  - Null model generation integration
  - Control data preparation
  - Edge case handling

### Integration Tests
- **`test_pipeline_integration.py`**: End-to-end pipeline tests
  - Full pipeline execution
  - Batch processing verification
  - Error handling scenarios
  - Output generation checks
  - Performance tests with large datasets

- **`test_pipeline.py`**: Original pipeline tests
  - Basic pipeline functionality
  - Component initialization
  - Data flow verification

### Test Utilities
- **`test_utils.py`**: Shared test utilities
  - `TestDataGenerator`: Creates realistic test data
  - `MockComponents`: Mock versions of heavy components
  - Assertion helpers for correlations and hypothesis results

## Running Tests

### Run All Tests
```bash
python run_tests.py
```

### Run Specific Test Categories
```bash
# Unit tests only
python run_tests.py unit

# Functional tests only
python run_tests.py functional

# Integration tests only
python run_tests.py integration

# Fast tests (excludes slow/performance tests)
python run_tests.py fast
```

### Run Specific Test File
```bash
python run_tests.py test_control_analyses.py
```

### Run with Coverage
Install pytest-cov first:
```bash
pip install pytest-cov
```

Then run tests normally - coverage will be automatically enabled.

## Test Data

Tests use synthetic data generated by `TestDataGenerator` which creates:
- Realistic conversation embeddings with temporal structure
- Multi-model embeddings with appropriate correlations
- Conversation metadata and phase annotations
- Invariance analysis results matching paper findings

## Key Test Scenarios

### Hypothesis Testing Scenarios
1. **All tiers pass**: High within-paradigm and cross-paradigm correlations
2. **Tier 1 fails**: Low within-paradigm correlations
3. **Tier 2 fails**: High within but low cross-paradigm correlations
4. **Control failures**: Patterns don't persist after controls

### Edge Cases Tested
- Empty conversation lists
- Missing trajectory metrics
- Single model type only
- Very short conversations
- Mismatched embedding dimensions
- Non-stationary temporal patterns

### Performance Tests
- 100+ conversations with batching
- GPU memory management
- Checkpoint functionality
- Large embedding dimensions (768)

## Mocking Strategy

Heavy components are mocked for speed:
- `EnsembleEmbedder`: Returns predictable embeddings
- `TrajectoryAnalyzer`: Returns realistic metrics
- Visualization components: Track calls without plotting
- File I/O: Uses temporary directories

## Adding New Tests

1. Place unit tests in files prefixed with `test_`
2. Use fixtures from `test_utils.py` for consistency
3. Mark slow tests with `@pytest.mark.slow`
4. Follow existing patterns for mocking
5. Ensure tests are independent and can run in any order

## Continuous Integration

Tests are designed to run in CI environments:
- No GUI dependencies
- Configurable output directories
- Proper cleanup of temporary files
- Reasonable timeouts for all tests