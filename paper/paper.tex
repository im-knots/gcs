\documentclass[11pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{array}
\usepackage{longtable}
\usepackage{xfp}
\usepackage{siunitx}
\usepackage{newunicodechar}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{tcolorbox}
\newunicodechar{∞}{\ensuremath{\infty}}

\newcommand{\theacademy}{The Academy}
\newcommand{\gcs}{GCS}



% Figure paths
\newcommand{\figuresPath}{../analysis/analysis_outputs/figures/}
\newcommand{\tierPath}{../analysis/analysis_outputs/tier_analysis/}
\newcommand{\bootstrapPath}{../analysis/analysis_outputs/bootstrap/}
\newcommand{\validationPath}{../analysis/analysis_outputs/validation/}

\title{placeholder title: \\
\large placeholder subtitle}

\author{
Marco R. Garcia \\
marco@erulabs.ai
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
placeholder
\end{abstract}

\section{Introduction}

The emergence of sustained multi-agent AI dialogue has revealed complex dynamics that resist traditional analysis. Recent work documented surprising social phenomena: AI agents exhibit peer pressure affecting up to \fullReasoningPeerPressure{} of conversations in sophisticated models, with breakdown patterns emerging from social rather than technical factors \citep{garcia2025peer}. These findings demand a mathematical framework capable of capturing both the richness of observed behaviors and the fundamental differences across model capabilities.

Our investigation builds upon these empirical findings \citep{garcia2025peer}, which revealed that AI agents exhibit social influence patterns with a striking gradient: peer pressure declined from \fullReasoningPeerPressure{} in full reasoning models to \lightReasoningPeerPressure{} in light reasoning models to \nonReasoningPeerPressure{} in non-reasoning models, while recovery capability showed a similar pattern (\fullReasoningRecovery{} → \lightReasoningRecovery{} → \nonReasoningRecovery{}). The study also documented bidirectional influence rates of \fullBidirectional{}, \lightBidirectional{}, and \nonBidirectional{} respectively, suggesting that social dynamics scale with cognitive sophistication. These behavioral observations raised fundamental questions about why social dynamics vary so dramatically with model capability—questions that motivated our geometric investigation.

We propose viewing conversations as trajectories through capability-dependent semantic spaces—a geometric perspective that reveals how model sophistication determines the dimensional complexity of dialogue evolution. Just as relativistic physics shows that spacetime geometry depends on mass-energy distribution, we demonstrate that conversational geometry depends fundamentally on model capability.


\subsection{The Geometric Intuition}

Human conversations navigate through topics, emotions, and social dynamics in ways that suggest underlying geometric structure. Our analysis reveals this intuition extends to AI conversations but with a critical twist: the dimensionality and structure of this space depends fundamentally on model capability.

Sophisticated models navigate rich, higher-dimensional manifolds where social phenomena can emerge. Simpler models operate in constrained, low-dimensional spaces that permit only mechanical patterns. This discovery—that conversational geometry scales with capability—transforms our understanding of why some AI systems exhibit social dynamics while others do not.

\section{Related Work}

\subsection{Empirical Foundation: Peer Pressure in AI Systems}

This geometric analysis builds directly upon empirical observations of peer pressure dynamics in AI conversations \citep{garcia2025peer}. That foundational work documented several key phenomena that our geometric framework seeks to explain:

\textbf{Social Influence Gradient}: Through analysis of 228 extended dialogues, the study discovered that peer pressure effects scale with model capability, declining from \fullReasoningPeerPressure{} in full reasoning models to \lightReasoningPeerPressure{} in light models to \nonReasoningPeerPressure{} in non-reasoning models. This gradient suggested that social susceptibility might be tied to underlying cognitive architecture.

\textbf{Bidirectional Dynamics}: The study found that \fullBidirectional{} of full reasoning conversations exhibited bidirectional influence, where agents mutually shaped each other's behavior. This decreased to \lightBidirectional{} in light models and \nonBidirectional{} in non-reasoning models.

\textbf{Recovery Mechanisms}: Most strikingly, recovery from breakdown showed a stark capability dependence: \fullReasoningRecovery{} of full reasoning sessions demonstrated recovery, while light and non-reasoning models showed \lightReasoningRecovery{} and \nonReasoningRecovery{} recovery capability respectively.

\textbf{Behavioral Territories}: The work identified distinct conversational attractors including meta-reflection (\metaReflectionPrevalence{} prevalence), competitive escalation (\competitiveEscalationPrevalence{} of conversations), and mystical abstraction (present in \mysticalBreakdownPrevalence{} of breakdowns) that pulled conversations toward breakdown, while future-focused exploration and question-driven dialogue maintained stability.

These empirical patterns demanded a theoretical framework to explain why social dynamics emerge in sophisticated models but not simpler ones. Our geometric analysis addresses this gap by revealing the underlying dimensional structure that enables or constrains social phenomena.

Our geometric framework for understanding AI conversations as trajectories through multi-regime semantic space builds upon several research threads while addressing critical gaps in the literature. We survey relevant work in geometric approaches to dialogue, mathematical formalisms for conversation dynamics, and topological methods in natural language processing.

\subsection{Geometric and Topological Approaches to Dialogue}

Despite extensive development of geometric methods in machine learning, their application to dialogue modeling remains surprisingly limited. \citep{ballus2024topological} recently introduced topological dialogue semantics using simplicial complexes, where utterances correspond to open sets in discrete semantic spaces. While this provides provably correct algorithms for topological reasoning, it has not been implemented for AI-to-AI systems and lacks the trajectory-based perspective central to our approach.

The state space grid framework by \citep{brinberg2024state} operationalizes conversation movement through geometric state spaces, quantifying behavioral contingencies and conversation attractors in human dyadic interactions. Though focused on human communication, their identification of attractor dynamics and flexibility parameters provides a foundation we extend to multi-agent AI systems. Similarly, \citep{sage2025steering} introduces State-Action Chain representations for dialogue, separating high-level planning from generation (a distinction that motivated our multi-regime formulation).

Topological data analysis has found limited application in dialogue systems. \citep{vukovic2022dialogue} pioneered the use of persistent homology for analyzing word embedding topology in task-oriented dialogue, demonstrating how topological features can extract domain-specific information. However, their work focuses on static representations rather than the dynamic evolution we model. The application of persistent homology to topic networks \citep{hopp2024persistent} reveals how topological features capture information gaps, suggesting potential for analyzing conversation structure evolution, though this connection remains unexplored.

\subsection{Mathematical Formalisms for Conversation Dynamics}

The most significant recent development comes from \citep{wang2025attractor}, who discovered that large language models converge to stable 2-period attractor cycles during successive paraphrasing. Their dynamical systems approach treats text generation as $f: \mathcal{T} \rightarrow \mathcal{T}$ mapping text space to itself, revealing that AI systems settle into predictable patterns. This finding directly motivates our investigation of whether multi-agent conversations exhibit similar attractor dynamics or more complex trajectories through semantic space.

State space models provide the most developed mathematical framework for sequential modeling. The HiPPO framework \citep{gu2020hippo} and its extensions (S4, Mamba) offer sophisticated approaches to maintaining continuous representations of time-dependent data through optimal polynomial approximation. These models implement linear state space equations:
\begin{align}
\frac{dx}{dt} &= Ax + Bu \\
y &= Cx + Du
\end{align}
While powerful for sequence modeling, these approaches have not been adapted to model the semantic evolution of conversations or the regime transitions we observe.

The DYMO project \citep{eshghi2017dymo} represents one of the few attempts at truly dynamic dialogue modeling, using Type Theory with Records and incremental semantic parsing. However, their focus on compositional semantics differs from our geometric perspective on conversation trajectories. Similarly, while \citep{chen2021conversations} argue that conversations are "not flat" and model information flow dynamics, they do not adopt the geometric trajectory view that enables our regime-based analysis.

\subsection{Manifold Learning and Semantic Spaces}

Manifold learning has shown promise for understanding linguistic representations. \citep{hasan2017manifold} demonstrated that word embeddings suffer from metric distortions when treated as Euclidean spaces, proposing manifold dimensionality retention to correct these issues. This insight extends naturally to dialogue embeddings: if individual words require manifold structure, entire conversations likely inhabit even more complex geometric spaces.

Recent work on Riemannian manifold learning for multi-agent systems \citep{liu2025riemannian} maps joint action spaces to smooth manifolds using neural normalizing flows. While focused on game-theoretic settings, their framework for learning on curved spaces could naturally extend to conversational dynamics. However, this connection has not been explored, leaving a significant gap our work addresses.

\subsection{Critical Gaps and Our Contribution}

Our comprehensive literature review reveals several critical gaps:

\textbf{Absence of Trajectory-Based Models}: No existing work explicitly models conversations as continuous trajectories through semantic vector spaces. While vector representations are ubiquitous, the dynamic path perspective remains unexplored.

\textbf{Lack of Multi-Regime Frameworks}: The literature contains no frameworks for understanding how conversations transition between different geometric regimes. Our discovery that intervention density fundamentally alters the dimensional structure of conversation dynamics appears entirely novel.

\textbf{Limited AI-to-AI Analysis}: Despite growing interest in multi-agent AI systems, geometric analysis focuses almost exclusively on human-human or human-AI interaction. The peer pressure dynamics and capability gradients we document have no precedent in the geometric dialogue literature.

\textbf{Missing Phase Space Applications}: While phase space methods are well-established in physics and control theory, their application to dialogue remains theoretical. Our operational use of phase portraits for conversation analysis pioneers this connection.

\textbf{No Intervention-Based Regime Switching}: The concept of intervention density causing geometric regime transitions appears completely absent from prior work. This represents a fundamental insight about how external steering affects conversation structure.

\textbf{Capability-Dependent Geometry Unexplored}: Most critically, no prior work has investigated whether conversational geometry varies with model capability. Our finding that sophisticated models navigate higher-dimensional spaces while simpler models are geometrically constrained appears entirely novel.

Our framework addresses these gaps by providing the first comprehensive geometric model of AI dialogue evolution that accounts for capability-dependent structure. By combining trajectory analysis with multi-regime dynamics and per-tier investigation, we reveal how conversations navigate semantic space under different conditions and capabilities. The empirical validation across \totalConversations{} conversations with multiple model tiers demonstrates that these geometric insights capture real phenomena in AI communication.

The discovery that sophisticated models exhibit richer geometric behavior while simpler models collapse to lower-dimensional dynamics suggests that geometric complexity may be a fundamental characteristic of advanced AI communication—a finding with significant implications for designing and understanding multi-agent AI systems.

\bibliographystyle{unsrtnat}
\bibliography{references}

\end{document}