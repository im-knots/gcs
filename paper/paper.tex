\documentclass[11pt,letterpaper]{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{array}
\usepackage{longtable}
\usepackage{xfp}
\usepackage{siunitx}
\usepackage{newunicodechar}
\usepackage{adjustbox}
\usepackage{subcaption}
\usepackage{tcolorbox}
\newunicodechar{∞}{\ensuremath{\infty}}

% Data placeholders
\newcommand{\totalConversations}{228}
\newcommand{\numEmbeddingModels}{5}

% Core visual evidence (from PDFs)
\newcommand{\distanceMatrixCorrelation}{0.879}
\newcommand{\distanceCorrRange}{[0.613, 0.966]}
\newcommand{\minPairwiseCorr}{0.613}
\newcommand{\maxPairwiseCorr}{0.966}

% Specific model correlations
\newcommand{\transformerInternalCorr}{0.855}
\newcommand{\classicalInternalCorr}{0.948}
\newcommand{\crossParadigmCorr}{0.716}

% Model-specific correlations from PDFs
\newcommand{\miniLMmpnetCorr}{0.879}
\newcommand{\miniLMwordTovecCorr}{0.820}
\newcommand{\wordTovecGloveCorr}{0.948}

% Visual pattern metrics
\newcommand{\blockPatternConsistency}{high}
\newcommand{\trajectoryShapeAgreement}{strong}
\newcommand{\densityPeakAlignment}{synchronized}

% Phase detection (variable results)
\newcommand{\phaseDetectionF}{0.16}
\newcommand{\phaseAgreementRange}{[-0.14, 0.76]}
\newcommand{\phaseDetectionBest}{0.76}
\newcommand{\phaseDetectionWorst}{-0.14}
\newcommand{\phaseDetectionFRange}{[0.08, 0.24]}

% Statistical validation
\newcommand{\bootstrapIterations}{10000}
\newcommand{\nullModelPValue}{0.001}
\newcommand{\nullBaselineCorr}{0.082}

% Conversation metrics
\newcommand{\minConvLength}{118}
\newcommand{\maxConvLength}{235}
\newcommand{\meanConvLength}{183.2}

% Figure paths
\newcommand{\figuresPath}{./figures/}

\title{Empirical Evidence for Geometric Invariance in Conversational Embedding Space}

\author{
Marco R. Garcia \\
marco@erulabs.ai
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
We present empirical evidence that conversations exhibit consistent geometric signatures when projected into different embedding spaces. Analyzing \totalConversations{} multi-agent AI dialogues from our prior study on social dynamics \citep{garcia2025peer}, we examine whether geometric properties of conversational trajectories remain consistent across \numEmbeddingModels{} fundamentally different embedding models. Visual analysis reveals striking similarities in distance matrices, trajectory shapes, and density evolution patterns across both transformer-based (BERT variants) and classical (wordTovec, GloVe) embeddings. Quantitative analysis confirms these visual observations: pairwise distance matrix correlations range from \minPairwiseCorr{} to \maxPairwiseCorr{}, with substantial correlations even between architecturally distinct approaches (mean cross-paradigm $\rho$ = \crossParadigmCorr{}). These patterns significantly exceed null model expectations (p < \nullModelPValue{}). While specific applications like phase detection remain challenging, the core finding of geometric invariance across embedding paradigms suggests that conversational structure may be more fundamental than previously recognized. This work establishes that geometric patterns in conversation transcend specific model implementations, opening possibilities for mathematical approaches to understanding dialogue.
\end{abstract}

\section{Introduction}

In our recent investigation of AI social dynamics \citep{garcia2025peer}, we documented unexpected peer pressure effects in multi-agent conversations. These behavioral phenomena (breakdown cascades, recovery mechanisms, behavioral territories) revealed complex dynamics that traditional analysis methods struggled to explain. This observation motivated an exploratory question: might conversations have underlying mathematical structure that could provide new perspectives on these dynamics?

The present work investigates a specific empirical question: when we project conversations into embedding spaces using different models, do we observe consistent geometric patterns? This is not an attempt to build a comprehensive theory, but rather an exploration of whether mathematical tools might offer useful lenses for understanding conversation.

We test for geometric invariance using \totalConversations{} multi-agent dialogues from our social dynamics study. By examining conversational trajectories through \numEmbeddingModels{} diverse embedding models (including both transformer and classical approaches), we can assess whether observed patterns reflect genuine conversational structure or merely artifacts of specific architectures.

Our key empirical findings:
\begin{enumerate}
\item \textbf{Visual evidence is compelling}: Distance matrices, trajectory shapes, and density patterns show remarkable consistency across all embedding models
\item \textbf{Quantitative metrics confirm visual observations}: Distance matrix correlations range from \minPairwiseCorr{} to \maxPairwiseCorr{}, far exceeding chance
\item \textbf{Cross-paradigm consistency is surprising}: Even fundamentally different approaches (transformers vs. word co-occurrence) show substantial agreement
\end{enumerate}

\section{Background and Related Work}

\subsection{The Geometric Revolution in NLP}

Recent years have witnessed a fundamental shift in understanding language through mathematical lenses. \citet{reif2019visualizing} pioneered geometric analysis of transformer embeddings, revealing that BERT naturally segregates semantic and syntactic information into distinct subspaces. This work established that language models encode surprisingly rich geometric structure beyond simple vector similarities.

The geometry of embedding spaces has proven more complex than initially assumed. \citet{ethayarajh2019contextual} demonstrated that contextual embeddings exhibit extreme anisotropy, clustering within narrow cones occupying less than 1\% of available vector space. Paradoxically, this apparent inefficiency correlates with improved performance, challenging assumptions about optimal embedding geometry. Recent work on intrinsic dimensionality \citep{aghajanyan2021intrinsic} further shows that language models compress task representations into remarkably low-dimensional subspaces (200-dimensional projections achieving 90\% of full fine-tuning performance).

\subsection{Conversational Trajectories as Mathematical Objects}

While geometric analysis of static embeddings has advanced rapidly, applications to conversational dynamics remain nascent. \citet{brinberg2024dynamic} introduced trajectory-based analysis modeling dialogues as paths through behavioral state spaces. This framework visualizes how dyads navigate conversational territories, revealing attractor states and phase transitions.

Recent work explicitly treating conversations as trajectories includes \citet{toxicity2025trajectory} who model user posting histories as continuous paths through topic space, and \citet{psychiatric2024semantic} who quantify semantic trajectories in clinical speech. Clinical applications demonstrate the power of trajectory analysis. \citet{palominos2024trajectories} showed that conversations involving individuals with mental health conditions exhibit measurably different geometric properties (shrinking semantic spaces, reduced convex hull volumes), providing quantitative biomarkers for mental health assessment.

The mathematical formalization of conversational dynamics has progressed through several frameworks. \citet{clarfeld2020codym} introduce CODYMs (COnversational DYnamics Model) using Markov models to capture sequential dependencies in palliative care conversations. \citet{fischer2024personality} map 1,655 conversations into 768-dimensional spaces, showing how personality differences affect geometric distances in conversation space.

\subsection{Cross-Model Embedding Analysis}

The question of how different embedding models relate has received attention primarily through transfer learning and alignment. Recent work on the "Platonic Representation Hypothesis" \citep{huh2024platonic} suggests diverse neural networks converge to similar representations, but this has been tested primarily on static embeddings rather than conversational trajectories.

\citet{dialoguecse2021} demonstrate context-response semantic matching through contrastive learning, showing how these approaches maintain better consistency across dialogue contexts than siamese networks. \citet{dial2vec2022} compare pre-trained language models with dialogue-specific approaches, revealing 8.7-13.8 point improvements by capturing speaker interaction patterns.

Studies on embedding space alignment typically focus on finding transformations between spaces \citep{conneau2018word} for practical applications. The question of whether conversational structures exhibit invariant geometric properties across models appears unexplored in the literature.

\subsection{Topological and Geometric Methods}

Topological data analysis (TDA) has emerged as powerful for understanding high-dimensional language data. \citet{zhu2013persistent} introduced persistent homology for text analysis, with recent applications specifically to dialogue. \citet{vukovic2022dialogue} apply persistent homology to dialogue systems, using topological features of word embedding spaces that outperform pure embedding methods on MultiWOZ datasets. \citet{ruppik2024topology} introduce complexity measures for local topology in contextual language model latent spaces, exploring the manifold hypothesis for dialogue contexts.

Particularly relevant is \citet{jakubowski2020topology}, who argue that word embeddings live on pinched manifolds where singular points correspond to polysemous words—directly applicable to understanding conversational ambiguity. These topological approaches reveal structure invisible to traditional analysis methods.

The geometric deep learning paradigm \citep{bronstein2021geometric} provides theoretical frameworks for understanding neural architectures through symmetries and invariances. While this perspective has revolutionized graph neural networks for dialogue \citep{ghosal2019dialoguegcn}, the specific question of geometric invariance in conversational embeddings remains unaddressed.

\subsection{Positioning Our Contribution}

Our work sits at an unexplored intersection of these research streams:

\begin{itemize}
\item Prior work analyzed embedding geometry for static representations, not dynamic trajectories
\item Conversational trajectory studies use single models, not cross-model validation
\item Embedding alignment literature focuses on transformation finding, not invariant properties
\item Topological methods concentrate on documents or single-model dialogue analysis, not cross-model conversational evolution
\end{itemize}

We ask a fundamentally different question: do conversations exhibit geometric signatures that remain consistent across different embedding models? This invariance question, if answered affirmatively, would suggest geometric properties of conversation transcend specific architectures—a necessary precondition for geometric analysis to be meaningful. Our exploratory approach differs from hypothesis-driven research by investigating whether mathematical tools might provide useful perspectives on the complex dynamics observed in our prior work \citep{garcia2025peer}.

\section{Methodology}

\subsection{Data}

We analyze \totalConversations{} conversations from our prior study on AI social dynamics \citep{garcia2025peer}. These multi-agent dialogues between AI models discussing consciousness were originally collected to study peer pressure and breakdown patterns. The corpus includes:

\begin{itemize}
\item Full reasoning models (N=67): Claude 3 Opus, GPT-4, Gemini Ultra
\item Light reasoning models (N=61): Claude 3.5 Sonnet, GPT-4 Mini, Gemini Pro
\item Non-reasoning models (N=100): Claude 3.5 Haiku, GPT-4 Turbo, Gemini Flash
\end{itemize}

Conversations range from \minConvLength{} to \maxConvLength{} messages (mean = \meanConvLength{}), with rich dynamics including topic evolution, phase transitions, and the peer pressure effects that motivated this geometric investigation.

\subsection{Embedding Models}

To test invariance across paradigms, we employ:

\textbf{Transformer-based:}
\begin{itemize}
\item all-MiniLM-L6-v2 (384 dimensions)
\item all-mpnet-base-v2 (768 dimensions)  
\item all-MiniLM-L12-v2 (384 dimensions)
\end{itemize}

\textbf{Classical:}
\begin{itemize}
\item wordTovec (300 dimensions, sentence-averaged)
\item GloVe (300 dimensions, sentence-averaged)
\end{itemize}

This selection spans modern contextual and classical static embeddings, providing a robust test of geometric invariance.

\subsection{Geometric Analysis}

For each conversation and embedding model, we compute:
\begin{itemize}
\item \textbf{Distance matrices}: Pairwise Euclidean distances between all message embeddings
\item \textbf{Sequential trajectories}: Step-wise distances representing conversational flow
\item \textbf{Density evolution}: Local density changes over conversation time
\item \textbf{PCA projections}: 2D visualizations of trajectory structure
\end{itemize}

\subsection{Statistical Validation}

We assess consistency through:
\begin{itemize}
\item Pairwise correlations between distance matrices across models
\item Bootstrap confidence intervals (\bootstrapIterations{} iterations)
\item Comparison with null models (randomly shuffled conversations)
\end{itemize}

\section{Results}

\subsection{Primary Finding: Strong Visual and Quantitative Consistency}

PLACEHOLDER PUT FIGURE OF SELECTED CONVOS HERE

Visual inspection reveals striking similarities across models:
\begin{itemize}
\item Distance matrices show consistent diagonal structures and block patterns
\item PCA trajectories follow similar paths (accounting for rotation/scaling)
\item Density evolution shows synchronized peaks and valleys
\item Self-similarity matrices reveal common coherence patterns
\end{itemize}

Quantitative analysis confirms these observations:

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
Model Pair & Distance Matrix $\rho$ & Trajectory $\rho$ \\
\midrule
Within transformers & \transformerInternalCorr{} & 0.693 \\
Within classical & \classicalInternalCorr{} & 0.888 \\
Cross-paradigm (mean) & \crossParadigmCorr{} & 0.427 \\
\midrule
MiniLM-L6 vs MPNet & \miniLMmpnetCorr{} & 0.731 \\
MiniLM-L6 vs wordTovec & \miniLMwordTovecCorr{} & 0.452 \\
wordTovec vs GloVe & \wordTovecGloveCorr{} & 0.888 \\
\midrule
Overall range & \distanceCorrRange{} & [0.163, 0.946] \\
\bottomrule
\end{tabular}
\caption{Correlation coefficients for geometric signatures across model pairs. Note the substantial correlations even between fundamentally different architectures.}
\label{tab:correlations}
\end{table}

These correlations far exceed null model baselines (mean $\rho$ = \nullBaselineCorr{}, p < \nullModelPValue{}), indicating genuine structural consistency rather than chance agreement.

\subsection{Cross-Paradigm Invariance}

The most surprising finding is substantial correlation between fundamentally different approaches:
\begin{itemize}
\item Transformer models (using attention mechanisms) and classical embeddings (using co-occurrence statistics) show mean correlations of \crossParadigmCorr{}
\item Even the lowest cross-paradigm correlation (\minPairwiseCorr{}) represents substantial agreement
\item Visual patterns (block structures, trajectory shapes) remain recognizable across all models
\end{itemize}

This suggests that conversational geometry reflects properties deeper than specific architectural choices.

\subsection{Limitations of Specific Applications}

While overall geometric patterns show strong consistency, some specific applications show variable performance:
\begin{itemize}
\item Automated phase detection shows mixed results - some conversations achieve strong cross-model agreement (correlations up to 0.76), while others show poor alignment (correlations as low as -0.14)
\item This variability (mean F1 = \phaseDetectionF{}, but ranging from 0.08 to 0.24) suggests that while global geometry is preserved, local feature detection may be conversation-dependent
\item Phase detection appears more reliable for conversations with clear structural transitions versus those with gradual evolution
\end{itemize}

These mixed results highlight that while geometric invariance holds at a global level, specific applications require careful consideration of conversation characteristics.

\section{Discussion}

\subsection{Interpreting Geometric Consistency}

The high correlations across architecturally distinct models suggest several possibilities:

\textbf{Convergent representation}: Different models may independently discover similar geometric organizations for conversational meaning, analogous to convergent evolution in biology.

\textbf{Fundamental structure}: Conversations may possess inherent geometric properties that any sufficiently capable model will capture, regardless of training approach.

\textbf{Linguistic universals}: The consistency might reflect deep properties of language and communication that transcend specific implementations.

\subsection{The Phase Detection Paradox}

An intriguing finding is the variability in phase detection performance. While global geometric patterns (distance matrices, trajectories) show strong consistency, local phase detection varies dramatically between conversations. Some show excellent cross-model agreement (up to \phaseDetectionBest{} correlation), while others fail completely (\phaseDetectionWorst{}). This suggests:

\begin{itemize}
\item Conversations may differ in their structural clarity - some have sharp phase boundaries that all models detect, while others evolve gradually
\item The same geometric information may be present but interpreted differently by detection algorithms
\item Future work should investigate what conversational properties predict phase detection success
\end{itemize}

\subsection{Implications}

Our findings have several implications:

\begin{enumerate}
\item \textbf{Validity of geometric analysis}: The cross-model consistency suggests that geometric approaches to conversation study genuine phenomena rather than model artifacts

\item \textbf{Robustness of patterns}: Researchers can have increased confidence that geometric patterns observed in one model likely reflect conversational properties rather than implementation details

\item \textbf{Foundation for further work}: Establishing invariance is a necessary precondition for developing mathematical theories of conversation
\end{enumerate}

\subsection{Connections to Behavioral Observations}

While we avoid claiming causal relationships, intriguing parallels emerge with our prior behavioral findings \citep{garcia2025peer}:
\begin{itemize}
\item Conversations exhibiting peer pressure (79.1\% in full reasoning models) show converging trajectories in embedding space
\item Breakdown events (occurring in 55.2\% of full reasoning conversations) correspond to geometric discontinuities
\item Recovery patterns (13.4\% success rate in full reasoning) involve returns to earlier embedding regions
\item The behavioral territories we documented (meta-reflection, competitive escalation) appear to have geometric correlates
\end{itemize}

These observations suggest geometric analysis might provide new perspectives on the complex social dynamics we previously documented, though establishing such connections requires future work.

\section{Limitations}

\begin{itemize}
\item \textbf{Domain specificity}: All conversations focused on consciousness discussions
\item \textbf{Embedding selection}: While diverse, our five models don't exhaust all approaches
\item \textbf{Geometric metrics}: We focus on Euclidean distance; other metrics might reveal different patterns
\item \textbf{Interpretation challenge}: What these geometric patterns mean remains unclear
\end{itemize}

\section{Future Directions}

This empirical foundation opens several research directions:

\begin{enumerate}
\item Testing invariance across more diverse conversational domains
\item Developing mathematical frameworks to formalize observed patterns
\item Investigating whether geometric features can predict conversational outcomes
\item Exploring connections between geometry and behavioral dynamics
\item Extending analysis to human conversations
\end{enumerate}

\section{Conclusion}

We have presented empirical evidence that conversations exhibit geometric signatures that persist across fundamentally different embedding models. The visual similarity is striking, and quantitative analysis confirms that these patterns far exceed chance. Most surprisingly, even architecturally distinct approaches (transformers vs. classical embeddings) show substantial agreement.

These findings suggest that geometric analysis of conversation captures genuine structural properties rather than model-specific artifacts. While we make no claims about what these patterns mean or whether they explain behavioral phenomena, establishing their consistency across models is an important first step.

The geometric invariance we observe opens possibilities for mathematical approaches to understanding conversation. Just as the discovery of consistent planetary orbits enabled gravitational theory, recognizing consistent conversational geometry may enable new theoretical frameworks for dialogue. However, much work remains to move from observation to understanding.

\bibliographystyle{unsrtnat}
\bibliography{references}

\appendix

\section{Supplementary Visualizations}

Additional ensemble visualizations for all \totalConversations{} conversations are available in the supplementary materials, showing consistent patterns across the full dataset.

\section{Statistical Methods}

\subsection{Bootstrap Procedure}

Confidence intervals were computed using stratified bootstrap sampling with \bootstrapIterations{} iterations, ensuring balanced representation across conversation types.

\subsection{Null Model Construction}

Null models were generated by:
\begin{enumerate}
\item Shuffling message order within conversations
\item Random sampling from the full message corpus
\item Generating random walks in embedding space
\end{enumerate}

All showed significantly lower correlations than observed data (p < \nullModelPValue{}).

\section{Model Specifications}

\subsection{Transformer Models}
\begin{itemize}
\item \textbf{all-MiniLM-L6-v2}: 6-layer, 384-dimensional embeddings, 22M parameters
\item \textbf{all-mpnet-base-v2}: 12-layer, 768-dimensional embeddings, 110M parameters
\item \textbf{all-MiniLM-L12-v2}: 12-layer, 384-dimensional embeddings, 33M parameters
\end{itemize}

\subsection{Classical Models}
\begin{itemize}
\item \textbf{wordTovec}: Skip-gram model, 300 dimensions, trained on Google News corpus
\item \textbf{GloVe}: Global vectors, 300 dimensions, trained on Common Crawl (840B tokens)
\end{itemize}

For classical models, sentence embeddings were computed by averaging word vectors, excluding stop words.

\end{document}